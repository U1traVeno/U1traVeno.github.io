---
layout:     post
title:      "Datawhale AIå¤ä»¤è¥ ç¬¬å››æœŸæ–¹å‘äºŒç¬”è®°"
subtitle:   "ä¸å¤§é¡¹ç›®çš„ç¬¬ä¸€æ¬¡æ¥è§¦"
date:       2024-08-12 17:19:00
author:     "U1traVeno"
header-img: "img/tag-bg.jpg"
tags:
    - Datawhale
    - AI
---

# Datawhale AIå¤ä»¤è¥ ç¬¬å››æœŸæ–¹å‘äºŒç¬”è®°

**åœ¨å¤ä»¤è¥ç»“æŸå‰ä¼šæŒç»­æ›´æ–°**

----------------

## Task1

å¤ä»¤è¥çš„ç¬¬ä¸€ä¸ªä»»åŠ¡

### Taskæ€»ç»“
æœ¬æ¬¡taskå¸¦ç€åƒæˆ‘è¿™ç§é›¶åŸºç¡€å°ç™½ä¸€æ­¥æ­¥å®ç°äº†åœ¨äº‘ç«¯éƒ¨ç½²ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥è¾…åŠ©æˆ‘ä»¬ç¼–ç¨‹ã€‚  
é€šè¿‡è¯¾åç²¾è¯»baselineä»£ç ï¼Œå¯ä»¥ç†è§£ç†Ÿæ‚‰å¦‚ä½•åœ¨ä»£ç ä¸­è°ƒç”¨apiï¼Œå¯¹æˆ‘è¿™æ ·çš„åªä¼šåŸºæœ¬è¯­æ³•çš„é€‰æ‰‹å¸®åŠ©ç”šå¤š  

### æµç¨‹  

#### Step0 å¼€é€šé˜¿é‡Œäº‘PAI-DSWè¯•ç”¨  

è·Ÿç€æ•™ç¨‹å°±å¥½å•¦~

#### Step1 åœ¨é­”æ­åˆ›å»ºPAIå®ä¾‹  

è¿™é‡Œä¹Ÿæ˜¯ç‚¹ç‚¹ç‚¹å°±å¥½äº†ã€‚ç»ˆç«¯ä¼¼ä¹æ˜¯ç±»unixå‘½ä»¤è¡Œï¼Œå¯¹æˆ‘è¿™ç§ç»å¸¸ç”¨linuxçš„ç©å®¶å¾ˆå‹å¥½(

#### Step2 Demoæ­å»º!  

æœ‰æœ‹å‹ç¢°åˆ°ä¸‹è½½æ…¢æˆ–è€…å¤±è´¥çš„é—®é¢˜ï¼Œå¯ä»¥æ›´æ¢pipé•œåƒæºæ¥è§£å†³  

è¿™é‡Œä¹Ÿæ˜¯è·Ÿç€æ•™ç¨‹ä¸€è·¯é¡ºåˆ©èµ°ä¸‹æ¥äº†~~è™½ç„¶æœ‰ç‚¹æ„Ÿè§‰æ‡µæ‡µçš„~~  

**ä¸èƒ½å¿˜è®°å›é­”æ­å…³é—­å®ä¾‹ï¼ï¼ï¼**
**ä¸èƒ½å¿˜è®°å›é­”æ­å…³é—­å®ä¾‹ï¼ï¼ï¼**
**ä¸èƒ½å¿˜è®°å›é­”æ­å…³é—­å®ä¾‹ï¼ï¼ï¼**

#### Baselineç²¾è¯»  

ä¹‹å‰çš„æ­¥éª¤éƒ½ç‚¹ç‚¹ç‚¹å°±å¥½äº†ï¼Œæ²¡å•¥éš¾åº¦ã€‚æˆ‘è§‰å¾—çœŸæ­£å¸å¼•æˆ‘çš„è¿˜æ˜¯åé¢çš„baselineç²¾è¯»ã€‚    

åœ¨è¿™è´´ä¸€ä¸ªbaselineä»£ç 
```python

# å¯¼å…¥æ‰€éœ€çš„åº“
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import streamlit as st

# åˆ›å»ºä¸€ä¸ªæ ‡é¢˜å’Œä¸€ä¸ªå‰¯æ ‡é¢˜
st.title("ğŸ’¬ Yuan2.0 æ™ºèƒ½ç¼–ç¨‹åŠ©æ‰‹")

# æºå¤§æ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
model_dir = snapshot_download('IEITYuan/Yuan2-2B-Mars-hf', cache_dir='./')
# model_dir = snapshot_download('IEITYuan/Yuan2-2B-July-hf', cache_dir='./')

# å®šä¹‰æ¨¡å‹è·¯å¾„
path = './IEITYuan/Yuan2-2B-Mars-hf'
# path = './IEITYuan/Yuan2-2B-July-hf'

# å®šä¹‰æ¨¡å‹æ•°æ®ç±»å‹
torch_dtype = torch.bfloat16 # A10
# torch_dtype = torch.float16 # P100

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè·å–æ¨¡å‹å’Œtokenizer
@st.cache_resource
def get_model():
    print("Creat tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(path, add_eos_token=False, add_bos_token=False, eos_token='<eod>')
    tokenizer.add_tokens(['<sep>', '<pad>', '<mask>', '<predict>', '<FIM_SUFFIX>', '<FIM_PREFIX>', '<FIM_MIDDLE>','<commit_before>','<commit_msg>','<commit_after>','<jupyter_start>','<jupyter_text>','<jupyter_code>','<jupyter_output>','<empty_output>'], special_tokens=True)

    print("Creat model...")
    model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch_dtype, trust_remote_code=True).cuda()

    print("Done.")
    return tokenizer, model

# åŠ è½½modelå’Œtokenizer
tokenizer, model = get_model()

# åˆæ¬¡è¿è¡Œæ—¶ï¼Œsession_stateä¸­æ²¡æœ‰"messages"ï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# æ¯æ¬¡å¯¹è¯æ—¶ï¼Œéƒ½éœ€è¦éå†session_stateä¸­çš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå¹¶æ˜¾ç¤ºåœ¨èŠå¤©ç•Œé¢ä¸Š
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# å¦‚æœç”¨æˆ·åœ¨èŠå¤©è¾“å…¥æ¡†ä¸­è¾“å…¥äº†å†…å®¹ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ“ä½œ
if prompt := st.chat_input():
    # å°†ç”¨æˆ·çš„è¾“å…¥æ·»åŠ åˆ°session_stateä¸­çš„messagesåˆ—è¡¨ä¸­
    st.session_state.messages.append({"role": "user", "content": prompt})

    # åœ¨èŠå¤©ç•Œé¢ä¸Šæ˜¾ç¤ºç”¨æˆ·çš„è¾“å…¥
    st.chat_message("user").write(prompt)

    # è°ƒç”¨æ¨¡å‹
    prompt = "<n>".join(msg["content"] for msg in st.session_state.messages) + "<sep>" # æ‹¼æ¥å¯¹è¯å†å²
    inputs = tokenizer(prompt, return_tensors="pt")["input_ids"].cuda()
    outputs = model.generate(inputs, do_sample=False, max_length=1024) # è®¾ç½®è§£ç æ–¹å¼å’Œæœ€å¤§ç”Ÿæˆé•¿åº¦
    output = tokenizer.decode(outputs[0])
    response = output.split("<sep>")[-1].replace("<eod>", '')

    # å°†æ¨¡å‹çš„è¾“å‡ºæ·»åŠ åˆ°session_stateä¸­çš„messagesåˆ—è¡¨ä¸­
    st.session_state.messages.append({"role": "assistant", "content": response})

    # åœ¨èŠå¤©ç•Œé¢ä¸Šæ˜¾ç¤ºæ¨¡å‹çš„è¾“å‡º
    st.chat_message("assistant").write(response)

```

å¯¹æˆ‘è¿™ç§åˆšå­¦äº†cs61açš„æ–°äººæ¥è¯´  
~~å®Œå…¨çœ‹ä¸æ‡‚å•Šå–‚~~  
ä¸è¿‡è‡ªå·±æ„Ÿè§‰è¿˜æ˜¯è¢«ä¸€å¤§æ®µä»£ç å“åˆ°äº†ã€‚å†·é™ä¸‹æ¥è‡ªå·±è¯»è¯»è¿˜æ˜¯èƒ½çŸ¥é“åœ¨åšä»€ä¹ˆçš„  

------------
